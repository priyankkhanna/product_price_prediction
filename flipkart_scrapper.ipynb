{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346bd9a9-d8f7-4dda-97e5-4a7466949200",
   "metadata": {},
   "source": [
    "## flipkart Scrapper using url.csv in flipkart_categories.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4034b8-93ae-4178-99a0-12c94c9cb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbb799-8b60-4a77-8cb1-e6099beba3a9",
   "metadata": {},
   "source": [
    "### From url to individual page links along with category and img links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075ad2a5-ca63-4d9e-a4cc-05ae8cc8e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_file = pd.read_csv('url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90cda70-2882-4bf4-ab8b-1ae0bfade7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = url_file['url'].to_numpy()\n",
    "cat1 = url_file['Category_1'].to_numpy()\n",
    "cat2 = url_file['Category_2'].to_numpy()\n",
    "cat3 = url_file['Category_3'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96de2389-e9e6-4bfd-b72b-8143f414f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "product_name=[]\n",
    "start_link = \"https://www.flipkart.com\"\n",
    "img_links = []\n",
    "category1 = []\n",
    "category2 = []\n",
    "category3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b06e9-7c11-4054-96b4-6769aab9410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for url,a,b,c in zip(url_list,cat1,cat2,cat3):\n",
    "    print(i)\n",
    "    try:\n",
    "        req = requests.get(url)\n",
    "        content = BeautifulSoup(req.content,'html.parser')\n",
    "        #works for iteration 1 with description\n",
    "        data = content.find_all('div',{'class':'_4ddWXP'}) \n",
    "        #works for iteration 2 usually such catergories have no description, specification, heading\n",
    "        data2 = content.find_all('div',{'class':'_1xHGtK _373qXS'})\n",
    "        #works for iteration 3 usually with review blocks inside the product block div. For products whose standard display of products is not available. In case available we do not require this as these will already be covered in above 2.\n",
    "        data3 = []\n",
    "        if not len(data2) and not len(data):\n",
    "          data3 = content.find_all('div',{'class':'_1Ni40J'})\n",
    "        for items in data:\n",
    "          res_link = items.find('a')['href']\n",
    "          img_link = items.find('img')['src']\n",
    "          links.append(start_link+res_link)\n",
    "          img_links.append(img_link)\n",
    "          category1.append(a)\n",
    "          category2.append(b)\n",
    "          category3.append(c)\n",
    "\n",
    "        for items in data2:\n",
    "          res_link = items.find('a')['href']\n",
    "          img_link = items.find('img')['src']\n",
    "          links.append(start_link+res_link)\n",
    "          img_links.append(img_link)\n",
    "          category1.append(a)\n",
    "          category2.append(b)\n",
    "          category3.append(c)\n",
    "\n",
    "        for items in data3:\n",
    "          res_link = items.find('a')['href']\n",
    "          img_link = items.find('img')['src']\n",
    "          links.append(start_link+res_link)\n",
    "          img_links.append(img_link)\n",
    "          category1.append(a)\n",
    "          category2.append(b)\n",
    "          category3.append(c)\n",
    "    except:\n",
    "        print(f'sorry brother for {url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf8c08-4383-44c1-98ac-168abce975c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Page Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67f93d2e-6a5c-471f-b2aa-0e45b75742d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \n",
       "1        \n",
       "2        \n",
       "3        \n",
       "4        \n",
       "       ..\n",
       "1833     \n",
       "1834     \n",
       "1835     \n",
       "1836     \n",
       "1837     \n",
       "Name: specifications, Length: 1838, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#product name string without processing Brand name is before \\x0 but not in all\n",
    "\n",
    "#rating string needs to be converted to number\n",
    "\n",
    "#purchase price string with rupee or dollar sign and commas\n",
    "\n",
    "#actual price string with rupee or dollar sign and commas\n",
    "\n",
    "#discount can be calculated (Not Included for now)\n",
    "\n",
    "#img url captured before in above step\n",
    "\n",
    "#rating of seller string decimal\n",
    "\n",
    "#seller name string\n",
    "\n",
    "#item description string ########## some products might not have description\n",
    "\n",
    "#Highlights string       ############### some products might not have highlights\n",
    "\n",
    "#specifications values only string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb04ad-0277-4496-ae3a-590daa2ac23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = []\n",
    "ratings = []\n",
    "sell_prices = []\n",
    "mrps = []\n",
    "sellers = []\n",
    "s_ratings = []\n",
    "descriptions = []\n",
    "highlights = []\n",
    "specifications = []\n",
    "i=1\n",
    "for link in links:\n",
    "  i=i+1\n",
    "  if i%20==0:\n",
    "        print(i)\n",
    "  req_page= requests.get(link) \n",
    "  content_page = req_page.content\n",
    "  data_page = BeautifulSoup(content_page,'html.parser')\n",
    "  try:\n",
    "    heading = data_page.find('h1').text\n",
    "  except:\n",
    "    heading = ' '\n",
    "  headings.append(heading)\n",
    "  try:\n",
    "    rating = data_page.find('div',{'class':'_3LWZlK'}).text\n",
    "  except:\n",
    "    rating = ' '\n",
    "  ratings.append(rating)\n",
    "  try:\n",
    "    sell_price = data_page.find('div',{'class':'_30jeq3 _16Jk6d'}).text\n",
    "  except:\n",
    "    sell_price = ' '\n",
    "  sell_prices.append(sell_price)\n",
    "  try:\n",
    "    mrp = data_page.find('div',{'class':'_3I9_wc _2p6lqe'}).text\n",
    "  except:\n",
    "    mrp = ' '\n",
    "  mrps.append(mrp)\n",
    "  try:\n",
    "    s = data_page.find('div',{'class':'_1RLviY'}).text\n",
    "    s=s[:s.find(data_page.find('div',{'class':'_3LWZlK _1D-8OL'}).text)]\n",
    "  except:\n",
    "    s = ' '\n",
    "  sellers.append(s)\n",
    "  try:\n",
    "    s_rating = data_page.find('div',{'class':'_3LWZlK _1D-8OL'}).text\n",
    "  except:\n",
    "    s_rating = ' '\n",
    "  s_ratings.append(s_rating)\n",
    "  try:\n",
    "    description = data_page.find('div',{'class':'_1mXcCf'}).text\n",
    "  except:\n",
    "    description = ' '\n",
    "  descriptions.append(description)\n",
    "  try:\n",
    "    highlight = ''\n",
    "    for li in data_page.find('div',{'class':'_2418kt'}).find_all('li'):\n",
    "      highlight= highlight + ' ' +li.text\n",
    "  except:\n",
    "    hightlight = ' '\n",
    "  highlights.append(highlight[1:])\n",
    "  try:\n",
    "    specification = ''\n",
    "    for li in data_page.find('div',{'class':'_3k-BhJ'}).find_all('td'):\n",
    "      specification= specification_val + ' ' +li.text\n",
    "  except:\n",
    "    specification = ' '\n",
    "  specifications.append(specification[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f7c1409-9f6c-42f8-8c91-aa81d699f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(\n",
    "    {\n",
    "     'category_1':category1,\n",
    "     'category_2':category2,\n",
    "     'category_3':category3,\n",
    "     'title':headings,\n",
    "     'product_rating':ratings,\n",
    "     'selling_price':sell_prices,\n",
    "     'mrp':mrps,\n",
    "     'seller_name':sellers,\n",
    "     'seller_rating':s_ratings,\n",
    "     'description':descriptions,\n",
    "     'highlights':highlights,\n",
    "     'specifications':specifications,\n",
    "     'image_links':img_links\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "925a5cd6-4a15-4f2a-9d7c-a74adc35840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('poc.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
